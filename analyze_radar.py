#!/usr/bin/env python3
# analyze_radar.py - Antigravity ë¶„ì„ ë„êµ¬
"""
Project_Radar.mdë¥¼ ì½ê³  ë¡œì»¬ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ ìƒì„±
Antigravityê°€ ì‹¤í–‰í•˜ê±°ë‚˜ ëŒ€í™”ë¡œ ìš”ì²­ ê°€ëŠ¥
"""

import os
from datetime import datetime
from collections import Counter

RADAR_FILE = "/Users/seunghoonoh/woonmok.github.io/Project_Radar.md"
OUTPUT_FILE = "/Users/seunghoonoh/woonmok.github.io/Radar_Insights.md"

CATEGORY_KEYWORDS = {
    "ë°°ì–‘ìœ¡/í‘¸ë“œí…Œí¬": ["ë°°ì–‘ìœ¡", "cultured meat", "cell-based", "fermentation", "ê· ì‚¬ì²´", "mycelium"],
    "ì‹í’ˆ ì•ˆì „": ["ë¦¬ìŠ¤í…Œë¦¬ì•„", "listeria", "fda", "ì‹í’ˆ ì•ˆì „", "ì˜¤ì—¼"],
    "í•˜ì´ì—”ë“œ ì˜¤ë””ì˜¤": ["ì˜¤ë””ì˜¤", "í•˜ì´ì—”ë“œ", "dsd", "dac", "ì•°í”„"],
    "AI/ì»´í“¨íŒ…": ["ai", "gpu", "blackwell", "nvidia", "ì„œë²„", "ì¸í”„ë¼"],
}


def _count_keywords(text):
    lower_text = text.lower()
    counts = {}
    for category, keywords in CATEGORY_KEYWORDS.items():
        counts[category] = sum(lower_text.count(keyword.lower()) for keyword in keywords)
    return counts


def _extract_relevant_lines(text, topic=None, limit=8):
    lines = [line.strip() for line in text.splitlines() if line.strip()]
    filtered = []
    if topic:
        topic_lower = topic.lower()
        for line in lines:
            if topic_lower in line.lower():
                filtered.append(line)
    else:
        filtered = lines
    return filtered[:limit]


def read_radar():
    """Project_Radar.md ì½ê¸°"""
    try:
        with open(RADAR_FILE, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return None


def analyze_trends(radar_content):
    """ì „ì²´ íŠ¸ë Œë“œ ë¶„ì„ (ë¡œì»¬ ê·œì¹™ ê¸°ë°˜)"""
    counts = _count_keywords(radar_content)
    top_categories = sorted(counts.items(), key=lambda item: item[1], reverse=True)
    top3 = [item for item in top_categories if item[1] > 0][:3]

    if not top3:
        top3 = top_categories[:3]

    risks = []
    lower_text = radar_content.lower()
    for keyword in ["ë¦¬ìŠ¤í…Œë¦¬ì•„", "listeria", "ì˜¤ì—¼", "ë¦¬ì½œ", "ê·œì œ", "ê³ ë¹„ìš©"]:
        if keyword.lower() in lower_text:
            risks.append(keyword)

    opportunities = []
    for keyword in ["ì ˆê°", "íš¨ìœ¨", "ë°œíš¨", "ìë™í™”", "í˜‘ì—…", "ì‹ ê·œ ì‹œì¥"]:
        if keyword.lower() in lower_text:
            opportunities.append(keyword)

    lines = ["# ğŸ”¥ ì „ì²´ íŠ¸ë Œë“œ ë¶„ì„", "", "## í•µì‹¬ íŠ¸ë Œë“œ (Top 3)"]
    for index, (category, score) in enumerate(top3, 1):
        lines.append(f"{index}. {category} (ì‹ í˜¸ ê°•ë„: {score})")

    lines.extend(["", "## âš ï¸ ì£¼ëª© ë¦¬ìŠ¤í¬"])
    if risks:
        lines.append("- " + ", ".join(sorted(set(risks))))
    else:
        lines.append("- ëšœë ·í•œ ë¦¬ìŠ¤í¬ í‚¤ì›Œë“œê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    lines.extend(["", "## ğŸ’¡ ê¸°íšŒ ìš”ì¸"])
    if opportunities:
        lines.append("- " + ", ".join(sorted(set(opportunities))))
    else:
        lines.append("- íš¨ìœ¨í™”/ì„±ì¥ í‚¤ì›Œë“œê°€ ì œí•œì ì…ë‹ˆë‹¤.")

    lines.extend(["", "## ğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ìš”ì•½"])
    for category, score in top_categories:
        lines.append(f"- {category}: {score}")

    lines.extend([
        "",
        "## ğŸ¯ ì¶”ì²œ ì•¡ì…˜ ì•„ì´í…œ",
        "- ìƒìœ„ ì¹´í…Œê³ ë¦¬ 1ê°œë¥¼ ì„ ì •í•´ ì´ë²ˆ ì£¼ ì‹¤í–‰ ê³¼ì œë¡œ ê³ ì •",
        "- ë¦¬ìŠ¤í¬ í‚¤ì›Œë“œ ë°œìƒ í•­ëª©ì€ ë³„ë„ ëª¨ë‹ˆí„°ë§ ì„¹ì…˜ìœ¼ë¡œ ë¶„ë¦¬",
        "- íš¨ìœ¨/ë¹„ìš© ì ˆê° ê´€ë ¨ í•­ëª©ì€ ìš°ì„ ìˆœìœ„ ìƒí–¥",
    ])
    return "\n".join(lines)


def search_topic(radar_content, topic):
    """íŠ¹ì • ì£¼ì œ ê²€ìƒ‰ ë° ë¶„ì„ (ë¡œì»¬ ê·œì¹™ ê¸°ë°˜)"""
    matches = _extract_relevant_lines(radar_content, topic=topic, limit=12)
    if not matches:
        return f"## ğŸ” '{topic}' ê²€ìƒ‰ ê²°ê³¼\n\n- ê´€ë ¨ í•­ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    lines = [f"## ğŸ” '{topic}' ê²€ìƒ‰ ê²°ê³¼", "", "### 1) ê´€ë ¨ ë‰´ìŠ¤ ëª©ë¡"]
    for index, line in enumerate(matches, 1):
        lines.append(f"{index}. {line}")

    lines.extend([
        "",
        "### 2) í•µì‹¬ í¬ì¸íŠ¸",
        f"- '{topic}' ê´€ë ¨ í•­ëª© {len(matches)}ê±´ ê°ì§€",
        "- ë°˜ë³µ ë“±ì¥í•œ í‘œí˜„ì„ ê¸°ì¤€ìœ¼ë¡œ ìš°ì„ ìˆœìœ„ ì„¤ì • ê¶Œì¥",
        "",
        "### 3) ì‹œì‚¬ì ",
        "- ê´€ë ¨ í•­ëª©ì„ ì£¼ê°„ ì‹¤í–‰ ë¦¬ìŠ¤íŠ¸ë¡œ ì „í™˜í•´ ì¶”ì ",
    ])
    return "\n".join(lines)


def weekly_summary(radar_content):
    """ì£¼ê°„ ìš”ì•½ ìƒì„± (ë¡œì»¬ ê·œì¹™ ê¸°ë°˜)"""
    counts = _count_keywords(radar_content)
    ordered = sorted(counts.items(), key=lambda item: item[1], reverse=True)
    highlights = [category for category, score in ordered if score > 0][:3]
    if not highlights:
        highlights = [category for category, _ in ordered[:3]]

    lines = [
        "# ğŸ“Š ì£¼ê°„ ì¸í…”ë¦¬ì „ìŠ¤ ë¦¬í¬íŠ¸",
        "",
        "## ğŸ¯ ì´ë²ˆ ì£¼ í•µì‹¬",
    ]
    for index, category in enumerate(highlights, 1):
        lines.append(f"- {index}) {category}")

    lines.extend(["", "## ğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ ë™í–¥"])
    for category, score in ordered:
        lines.append(f"- {category}: ì‹ í˜¸ {score}")

    lines.extend([
        "",
        "## ğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸",
        "- ì‹ í˜¸ê°€ ë†’ì€ ì¹´í…Œê³ ë¦¬ì— ë¦¬ì†ŒìŠ¤ë¥¼ ì§‘ì¤‘í•˜ëŠ” ê²ƒì´ ìœ ë¦¬í•©ë‹ˆë‹¤.",
        "",
        "## ğŸ”® ë‹¤ìŒ ì£¼ ì „ë§",
        "- ìƒìœ„ ì¹´í…Œê³ ë¦¬ ì¶”ì„¸ ìœ ì§€ ì—¬ë¶€ì™€ ë¦¬ìŠ¤í¬ í‚¤ì›Œë“œ ì¬ë“±ì¥ ì—¬ë¶€ë¥¼ ì¶”ì í•˜ì„¸ìš”.",
    ])
    return "\n".join(lines)


def save_insights(content, mode="append"):
    """ì¸ì‚¬ì´íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    if mode == "overwrite" or not os.path.exists(OUTPUT_FILE):
        header = f"""# ğŸ” Radar Insights - ë¶„ì„ ë¦¬í¬íŠ¸

**ìƒì„± ì‹œê°**: {timestamp}
    **ë¶„ì„ ì—”ì§„**: Local Rule Engine

---

"""
        with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
            f.write(header + content)
    else:
        with open(OUTPUT_FILE, "a", encoding="utf-8") as f:
            f.write(f"\n\n---\n## [{timestamp}] ì—…ë°ì´íŠ¸\n\n{content}\n")


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("ğŸ” Radar ë¶„ì„ ë„êµ¬ ì‹œì‘...")
    
    # Radar ì½ê¸°
    radar_content = read_radar()
    if not radar_content:
        print("âŒ Project_Radar.mdë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ… Radar ë°ì´í„° ë¡œë“œ ì™„ë£Œ ({len(radar_content)} ë¬¸ì)")
    
    # ë©”ë‰´
    print("\në¶„ì„ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print("1. ğŸ”¥ ì „ì²´ íŠ¸ë Œë“œ ë¶„ì„")
    print("2. ğŸ“Š ì£¼ê°„ ìš”ì•½ ë¦¬í¬íŠ¸")
    print("3. ğŸ” íŠ¹ì • ì£¼ì œ ê²€ìƒ‰")
    
    choice = input("\nì„ íƒ (1-3): ").strip()
    
    if choice == "1":
        print("\nğŸ”„ ì „ì²´ íŠ¸ë Œë“œ ë¶„ì„ ì¤‘...")
        insights = analyze_trends(radar_content)
        save_insights(insights, mode="overwrite")
        print(f"\nâœ… ë¶„ì„ ì™„ë£Œ!\n\n{insights}\n")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {OUTPUT_FILE}")
        
    elif choice == "2":
        print("\nğŸ”„ ì£¼ê°„ ìš”ì•½ ìƒì„± ì¤‘...")
        summary = weekly_summary(radar_content)
        save_insights(summary, mode="overwrite")
        print(f"\nâœ… ìš”ì•½ ì™„ë£Œ!\n\n{summary}\n")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {OUTPUT_FILE}")
        
    elif choice == "3":
        topic = input("\nê²€ìƒ‰í•  ì£¼ì œ ì…ë ¥ (ì˜ˆ: ë°°ì–‘ìœ¡, ë¦¬ìŠ¤í…Œë¦¬ì•„, GPU): ").strip()
        print(f"\nğŸ”„ '{topic}' ê²€ìƒ‰ ì¤‘...")
        result = search_topic(radar_content, topic)
        print(f"\nâœ… ê²€ìƒ‰ ì™„ë£Œ!\n\n{result}\n")
        
        save = input("\nê²°ê³¼ë¥¼ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
        if save == 'y':
            save_insights(f"## ğŸ” '{topic}' ê²€ìƒ‰ ê²°ê³¼\n\n{result}", mode="append")
            print(f"ğŸ“ ì €ì¥ ì™„ë£Œ: {OUTPUT_FILE}")


if __name__ == "__main__":
    main()
